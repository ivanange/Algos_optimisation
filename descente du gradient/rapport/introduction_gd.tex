\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage[affil-it]{authblk}
\usepackage[utf8]{inputenc} % un package
\usepackage[T1]{fontenc}      % un second package
\usepackage[francais]{babel}  % un troisième package
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{array}
%\usepackage[figurename=Fig.]{caption}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry} %les marges
\usepackage{array}
\usepackage{listings}
\usepackage{color}
\usepackage{tabularx}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}



\date{} % Pour mettre la date du jour, tapez \today.


\begin{document}
\author{ONANA Damase  Donald}
\title{Introduction à la méthode de Descente du Gradient et application au Machine Learning }
\affil{Département d'Informatique, Université de Yaoundé I}
\date{\today}

\maketitle
\vspace{0.8in}
\section{Introduction et Definition} 

L'algorithme de la descente du gradient est un algorithme d'optimisation continue différentiable (ou de premier ordre) . Il est particulièrement destiné au problème d'optimisation (\textit{P}) sans contrainte  ayant pour fonction objective une fonction $f : R^{d} \rightarrow R$ continue et totalement différentiable. Encore connue sous le nom d'algorithme  de  la  plus  forte  pente ou de la plus  profonde  descente  (steepest  descent, en anglais), la descente du gradient est un algorithme itératif qui procède par amélioration successives et est complètement basé sur le calcul du gradient $\nabla_{\theta}{f}$ par rapport à un paramètre $\theta$ de la fonction \textit{f} à maximiser ou minimiser.\\
En effet une des formulations possible du problème d'optimisation (\textit{P}) est celle de devoir optimiser un paramètre $\theta$ dont dépend la fonction \textit{f} , c'est à dire que l'on cherche à converger vers un $\theta^{*}$ tel que : 
\vspace{0.2in}
\begin{large}
\begin{equation}
\frac{\partial{f(\theta^{*})}}{\partial{\theta^{*}}} = 0
\end{equation}
\end{large}
\vspace{0.2in}


En d'autres termes , chercher à maximiser ou minimiser \textit{f} revient à chercher un $\theta^{*}$ appelé point stationnaire tel que $f(\theta^{*})$ soit le plus grand possible (pour un problème de maximisation) ou le plus petit possible (pour un problème de minimisation). Pour le faire l'algorithme de descente du gradient fonctionne comme suite : \\

\begin{enumerate}
\item On choisit une valeur initiale $\theta^{0}$ du paramètre  \\	
\item On modifie la valeur courante du paramètre en se déplaçant dans la direction opposée au gradient (pour une minimisation) c'est à dire : 
	\vspace{0.2in}
	\begin{large}
	\begin{equation}
	\theta^{t+1}=\theta^{t}-\eta \frac{\partial{f(\theta^{t})}}{\partial{\theta^{t}}}
	\end{equation}
	\end{large}
	
où $\eta$ est le pas ou encore taux d'apprentissage qui détermine la vitesse de convergence. On en reparlera mieux aux sections suivantes . \\

\item L'on répète l'étape 2 jusqu'à la convergence . \\
\end{enumerate}
Notons que nous avons juste considéré le cas d'une minimisation comme nous le ferons la plus part du temps aux sections suivantes , tout en se rappelant que pour maximiser une fonction il suffit de minimiser son opposé ou alors dans notre cas se déplacer dans la direction du gradient plutôt que dans la direction opposée comme nous l'avons fait à l'étape 2. Il est tout aussi important de noter que le point stationnaire $\theta^{*}$ trouvé est en fait soit un point de minimum local ou global (pour un problème de minimisation) , soit un point de maximum local ou global (pour un problème de maximisation) ou alors un point selle (qui est maximum et minimum). Si notre fonction \textit{f} est une fonction convexe alors l'optimisation sera toujours parfaite et donc $\theta^{*}$ sera toujours un point de maximum ou de minimum global , dans le cas ou \textit{f} est une fonction non convexe voir fortement non convexe l'on trouvera souvent voir toujours des points de maximum ou de minimum locaux. \\


Cet algorithme fait aujourd'hui parti des algorithmes d'optimisation les plus populaire et les plus utilisés notamment en informatique pour des problèmes d'apprentissage automatique (\textit{machine learning}). En effet une formulation mathématique d'un problème d'apprentissage automatique nous renvoi à un problème d'optimisation avec ou sans contrainte , dans ce cas l'algorithme de descente du gradient associé aux réseaux de neurones est aujourd'hui jugée comme une des méthodes la plus satisfaisante pour résoudre ce genre de problème. Une des preuves de la popularité de cet algorithme est le fait qu'il est implémenté dans toutes bibliothèques (logiciel) traitant des problèmes d'apprentissage automatique profond (deep learning) . La descente du gradient du haut de sa popularité et de son efficacité mérite une attention particulière c'est à dire une étude du concept, des ses différentes variantes , de leurs défauts et qualités ainsi que sur les améliorations apportées .

\section{Les variantes de la Descente de Gradient}  

L'on distingue principalement 03 variantes de l'algorithme : \\
\begin{itemize}
\item Le bacht ou standart gradient descent; \\

\item le stochastic ou online gradient descent; \\

\item le mini-bacht gradient descent \\

\end{itemize} il serait difficile de dire qu'une variante est largement par rapport aux autres , tous dépend d'un certains nombres de paramètres comme par exemple le nombre de données disponible, l'environnement d'exécution ou la qualité du résultat voulue. \\

\subsection{Bacht Gradient Descent}

Le bacht gradient descent encore appelé standart gradient descent est comme son nom l'indique la version standard de l'algorithme. Ici, l'on calcul le gradient de la fonction objective par rapport à $\theta$ en considérant l'ensemble de données d'entrainement disponible .
\vspace{0.2in}
\begin{large}
\begin{equation}
\theta = \theta - \eta \nabla_{\theta}f(\theta)
\end{equation}
\end{large}

Cette variante a la particularité d'être lente surtout lorsque le jeu de données d'entrainement est très grand, dans ce cas il est préférable d'utiliser l'une des deux autres variantes . \\
Le pseudo code suivant d'écrit plus en détail la variante bacht de la descente du gradient.

\begin{center}
\begin{algorithm}[H]
\caption{BGD($ D = \lbrace (x_{1},y_{1})...(x_{n},y_{n}) \rbrace, n\_epoch, \eta$)}
\begin{algorithmic} 
\STATE Initialiser $\theta^{0}$
\STATE $E_{0} = 0$
\FOR{$i=1$ \TO $n\_epoch$ } 
\FORALL{$(x_{d},y_{d})$ in D } 
\STATE $y_{pred} = get\_prediction(\theta^{i}, x_{d})$
\STATE $E_{t} = E_{t-1} + get\_error(y_{pred}, y_{d})$
\ENDFOR
\STATE caluler $\nabla E(\theta )$
\STATE $\theta^{i} = \theta^{i-1} - \eta\nabla E(\theta ) $
\ENDFOR
\RETURN $\theta^{i}$
\end{algorithmic}
\end{algorithm}
\end{center}

\vspace{0.2in}

\subsection{Stochastic Gradient Descent}

L'algorithme stochastic de descente du gradient contrairement à la variante bacht, calcul le gradient de la fonction objective par rapport à $\theta$ pour chaque instance ($x_{i}, y_{i}$) des données d'entrainement .
\vspace{0.2in}
\begin{large}
\begin{equation}
\theta = \theta - \eta \nabla_{\theta}f(\theta, x_{i}, y_{i})
\end{equation}
\end{large}

Le fait que la variante stochastic calcul le gradient et mette directement à jour le paramètre pour chaque instance ($x_{i}, y_{i}$) des données d'entrainement, rend la convergence largement plus rapide qu'à la version bacht, mais par contre elle sera un peu moins précise. \\
Le pseudo code suivant d'écrit la variante stochastic de la descente du gradient.

\begin{center}
\begin{algorithm}[H]
\caption{SGD($ D = \lbrace (x_{1},y_{1})...(x_{n},y_{n}) \rbrace, n\_epoch, \eta$)}
\begin{algorithmic} 
\STATE Initialiser $\theta^{0}$
\STATE $E_{0} = 0$
\FOR{$i=1$ \TO $n\_epoch$ } 
\STATE shuffle(D)
\FORALL{$(x_{d},y_{d})$ in D } 
\STATE $y_{pred} = get\_prediction(\theta^{i}, x_{d})$
\STATE $E_{t} = E_{t-1} + get\_error(y_{pred}, y_{d})$
\STATE caluler $\nabla E(\theta )$
\STATE $\theta^{i} = \theta^{i-1} - \eta\nabla E(\theta ) $
\ENDFOR
\ENDFOR
\RETURN $\theta^{i}$
\end{algorithmic}
\end{algorithm}
\end{center}

\vspace{0.2in}

\subsection{Mini-Bacht Gradient Descent}
La version mini-bacht de la descente du gradient essaie de prendre le meilleur de la version bacth et stochastic . Ici , l'on calcul le gradient et on met à jour le paramètre pour chaque mini lots de l'ensemble de données d'entrainement.

\begin{large}
\begin{equation}
\theta = \theta - \eta \nabla_{\theta}f(\theta, x_{i:i+n}, y_{i:i+n})
\end{equation}
\end{large}

La véritable difficulté ici est de trouver la valeur de l'hyperparamètre n qui définit la taille de chaque lot ( Bacht size en anglais ) . Comme le dit Sebastian Ruder dans \cite{ref1} l'on prend communément une valeur comprise entre 50 et 256 pour cet hyperparamètre cela dépend vraiment de la tache qu'on effectue et de l'objectif à atteindre. Mais une fois qu'aprés plusieurs expérience et observation l'on parvient à trouver la valeur adéquate , la version mini-bacht offre des avantages tels que la diminution de la fréquence de mise à jour ce qui à pour conséquence de rendre la convergence plus stable, ou alors prise en compte du calcul vectoriel possible qui vas rendre le calcul du gradient beaucoup plus rapide et simple.\\ 
Le pseudo code suivant d'écrit la variante mini-bacht de la descente du gradient.

\begin{center}
\begin{algorithm}[H]
\caption{mini\_bacht($ D = \lbrace (x_{1},y_{1})...(x_{n},y_{n}) \rbrace, n\_epoch, \eta, bacht\_size$)}
\begin{algorithmic} 
\STATE Initialiser $\theta^{0}$
\STATE $E_{0} = 0$
\FOR{$i=1$ \TO $n\_epoch$ } 
\STATE shuffle(D)
\FOR{bacht \textbf{in} get\_bacht(D, bacht\_size)} 
\FORALL{$(x_{d},y_{d})$ in bacht } 
\STATE $y_{pred} = get\_prediction(\theta^{i}, x_{d})$
\STATE $E_{t} = E_{t-1} + get\_error(y_{pred}, y_{d})$
\STATE caluler $\nabla E(\theta )$
\STATE $\theta^{i} = \theta^{i-1} - \eta\nabla E(\theta ) $
\ENDFOR
\ENDFOR
\ENDFOR
\RETURN $\theta^{i}$
\end{algorithmic}
\end{algorithm}
\end{center}


\section{Application à un Problème de machine Learning}

Dans cette section nous allons appliquer ce qui a été vue au section précédente pour essayer de résoudre un problème de machine learning plus précisément le problème de régression linéaire . Nous commençons d'abord par présenté la formulation du problème , ensuite nous utiliserons successivement les 3 variantes de l'algorithme de descente du gradient pour le résoudre. Et à la section suivante , nous effectuerons une étude comparative des résultats et des performances de chacune des variantes.

\subsection{Le probléme de regression linéaire}

Comme définit dans \cite{ref2}, l'analyse pas régression est à l'initial une technique statistique permettant d'estimer une possible relation de causes à effet entre des variables. De manière  un peu plus explicite dans \cite{ref4} l'on définit l'analyse par régression comme étant une méthode pour découvrir la relation entre une ou plusieurs variables de réponses (également appelées variables dépendantes, variables expliquées, variables prédites ou régressandes, généralement désignées par y) et des variables prédicteurs (également appelés variables indépendantes, variables explicatives, variables de contrôle ou régresseurs, généralement désignés par $x_{1},x_{2},...,x_{p}$).\\

Dans la littérature, il existe 03 type de regression, à savoir : 

\begin{itemize}
\item La régression linéaire simple ou univarié : où on essai de modéliser une relation linéaire entre deux variables, l'une d'elle étant la variable dépendante (\textit{y}) et l'autre la variable indépendante (\textit{x}). Elle est très souvent formalisée par l'équation suivante
\begin{large}
\begin{equation}
y = \beta_{1}x + \beta_{0} + \epsilon
\end{equation}
\end{large}

\item La régression linéaire multiple : où l'on cherche à modéliser une relation relation linéaire entre une variable dependente et plusieurs variables indépendante. Formellement on a 

\begin{large}
\begin{equation}
y = \beta_{0} + \beta_{1}x_{1} + ... + \beta_{p}x_{p} + \epsilon
\end{equation}
\end{large}

\item La régression non linéaire  : l'on suppose que la relation entre la variable dépendante et les variables indépendantes est
non linéaire . Un exemple de modèle de régression non linéaire (modèle de croissance) peut s'écrire : 

\begin{large}
\begin{equation}
y = \frac{\alpha}{1+e^{\beta t}} + \epsilon
\end{equation}
\end{large}

où y est la croissance d'un organisme particulier en fonction du temps t, $\beta$ et $\alpha$ sont les paramètres du modèle, et $\epsilon$ est l'erreur aléatoire. \\

\end{itemize}

Les objectifs de l'analyse de régression sont triples : 

\begin{enumerate}
\item Pouvoir établir une relation entre la variable dépendante et les variables indépendante ; \\

\item Pouvoir prédire la variables dépendante à partir des variables indépendante ;\\

\item Observer les variables indépendantes et dire lesquelles sont importantes pour expliquer la variables dépendante \\
\end{enumerate}

Dans notre étude , nous ferons face à un problème de régression linéaire simple et nous supposerons qu'il existe une relation linéaire entre les deux variables, notre défis sera donc de pouvoir prédire les variables dépendante à partir des variables indépendantes .\\

\subsection{Résolution par la méthode Bacht}

L'on rappelle que notre objectif est de pouvoir trouver $\beta_{0}^{*}$ et $\beta_{1}^{*}$ de manière à minimiser au tant que possible la fonction d'erreur $E = (y_{i} - y_{pred}^{i})$ avec $y_{pred}^{i} = \beta_{1}x_{i} + \beta_{0} $ . On applique donc l'algorithme 1 et on trouve finalement $\beta_{0} = 1.15$ , $\beta_{1} = 71.35$ . La figure suivante nous montre la représentation du nuage de points et la droite (\textit{D}) d'équation $y = \beta_{1}x_{i}^{*} + \beta_{0}^{*} $ (pour i de 1 à n).\\


\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.65]{../../images/bacht.png}
\end{center}
\caption{Le nuage de point et la droite de régression trouvée avec la méthode bacht}
\end{figure}
\vspace{0.2in}


La droite (\textit{D}) représenté en rouge est donc appelé  droite de régression de y en x , elle représente la relation linéaire entre les variables $y_{i}$ et $x_{i}$. On observe ensuite à l'image suivante l'évolution de l'erreur E au cour des itérations. \\
\newpage

\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.80]{../../images/bacht_error.png}
\end{center}
\caption{Evolution de l'erreur en fonction des itérations (méthode Bacht)}
\end{figure}
\vspace{0.2in}

l'on voix bien qu'à la première itération, on a une erreur assez grande et au cour de l'exécution de l'algorithme on optimise les paramètres  $\beta_{0}$ et $\beta_{1}$ pour finalement obtenir à la dernière itération une erreur plus petite (jugée la plus petite possible) .\\

\subsection{Résolution par la méthode Stochastic}

Comme nous l'avons fait pour la variante bacht, on implémente aussi la variante stochastic présenté à l'algorithme 2 . Et on trouve $\beta_{0} = 1.316$ , $\beta_{1} = 71.294$ . La figure suivant nous montre le nuage de point et la droite de régression trouvé .

\vspace{0.2in}
\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.65]{../../images/stochastic.png}
\end{center}
\caption{Le nuage de point et la droite de régression trouvée avec la méthode Stochastic}
\end{figure}
\vspace{0.2in}

On observe ensuite à l'image suivante l'évolution de l'erreur E au cour des itérations pour la version stochastic . \\

\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.55]{../../images/stochastic_error.png}
\end{center}
\caption{Evolution de l'erreur en fonction des itérations (méthode stochastic)}
\end{figure}


Cette figure confirme bel et bien nos propos précédent qui disait que , avec la méthode stochactic on observe beaucoup de fluctuation de la fonction objective (dans ce cas la fonction d'erreur) ce qui rend convergence moins stable.

\subsection{Résolution par la méthode Mini Bacht}

Apres avoir implémenter la version bacht pour un bacht\_size de 25 pour un jeu de données de taille 100 , on trouve $\beta_{0} =1.1362$ , $\beta_{1} = 71.8050$ . La figure suivant nous montre le nuage de point et la droite de régression trouvé .

\vspace{0.2in}
\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.65]{../../images/mini_bacht.png}
\end{center}
\caption{Le nuage de point et la droite de régression trouvée avec la méthode Stochastic}
\end{figure}

\newpage
On observe ensuite à l'image suivante l'évolution de l'erreur E au cour des itérations pour la version mini\_bacht


\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.55]{../../images/mini_bacht_error.png}
\end{center}
\caption{Evolution de l'erreur en fonction des itérations (méthode stochastic)}
\end{figure}
\vspace{0.2in}  


\section{Etude Comparative }

Dans cette section nous analyserons la qualités des résultats aux sections précédentes ainsi que la manière dont ils ont été obtenus pour chacune des variantes et faire des comparaison . \\

Nous commençons pas présenter un tableau récapitulatif des résultats obtenus . \\

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
   & Bacht & stochastic & Mini-Bacht \\ \hline

MSE  & 583.924 & 348.879 & 688.295
	

\\ \hline

Nombre d'itérations (fixés)   & 450 & 450 & 450
	

\\ \hline

Nombres de mise à jour  & 450 & 45000 & 1800
	

\\ \hline


$\beta_{1}$  & 71.0745 & 71.6831 & 71.8122
	

\\ \hline


$\beta_{0}$  & 1.5600 & 1.1194 & 1.1287
	

\\ \hline
	
\end{tabular}
\end{center}

\vspace{0.2in}

Le premier constat est que, bien que pour cette expérience le MSE de  la variante stochastique est inférieur aux autres elle est par contre beaucoup moins stable dû au très grand nombres de mise à jour . Avec un Bacht size de 25 , la convergence version mini bacht est un peu plus stable et si on augmente la valeur du bacht size  , on se rapprocherait du comportement exactement de la variante bacht . Pareillement si l'on diminue le bacht size on se rapproche de la variante stochastique avec une convergence moins stable , la figure suivante illustre un peu tout cela . 


\newpage
\begin{figure}[here]
\begin{center}
\includegraphics[scale=0.55]{../../images/bacht_size.png}
\end{center}
\caption{La méthode mini-bacht avec différents bacht size}
\end{figure}
\vspace{0.2in} 

L'on constate qu'avec un bach size égale à 1 , la version mini bacht et la version stochastique sont semblable pareil lorsque le bach size grimpe jusqu'à 100  la version bacht et la version mini bacht deviennent semblable.\\

Ensuite pour apprécier encore plus la qualité et la vitesse de convergence de chacune des variantes , nous devons ajouter une condition d'arrêt outre que celle sur les itérations . Il s'agit de la condition d'arrêt sur l'amélioration insuffisante , formellement l'algorithme s'arrêtera lorsque la condition suivante sera respecté :  



\newpage
\bibliographystyle{plain} % Le style est mis entre accolades.
\bibliography{biblio}
\end{document}

